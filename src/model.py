# -*- coding: utf-8 -*-
"""Persian prosody detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lNzqKGMEf8bXxRIcgci1h6_2NuGbLe6I

# Pre setup 
- remove extra sample data directory
"""

!rm -rf sample_data

"""# Data
- uploading data
- add dataloader generator
"""

!unzip data.zip
!rm data.zip

def read_lines(path):
  with open(path) as file:
    return file.readlines()

def make_data_loader(develeopment):
  postfix = 'Trn' if develeopment else 'Tst'
  postfix += '-v2.00.txt'

  udashs = read_lines(f"./data/DSUS{postfix}")
  answer = read_lines(f"./data/DSA{postfix}")
  tokens = read_lines(f"./data/DSVN{postfix}")

  tokens = tokens[: len(answer)]

  for t, u, a in zip(tokens, udashs, answer):
    yield t.strip(), u.strip(), a.strip()

for pack in make_data_loader(True):
  print(pack)
  break

"""# Phoneme"""

!pip install --upgrade https://github.com/PasaOpasen/PersianG2p/tarball/master

from PersianG2p import Persian_g2p_converter
PersianG2PConvertor = Persian_g2p_converter(use_large=True)
g2p = PersianG2PConvertor.transliterate

print(pack[0])
g2p(pack[0].replace("*", " "), tidy=False)

g2p('فعلاتن مفاعلن فعلن', tidy=False)

"""# Asnwers

## Prostody types
"""

prostody_categories = """1001
U U - - U U - - U U - - U U -
fA?elAton fa?alAton fa?alAton fa?alon
فعلاتن فعلاتن فعلاتن فعلن
رمل مثمن مخبون محذوف
1002
U - U - U U - - U - U - U U -
mafA?elon fa?alAton mafA?elon fa?elon
مفاعلن فعلاتن مفاعلن فعلن
مجتث مثمن مخبون محذوف
1003
- - U - U - U U - - U - U -
maf?ulo fA?elAto mafA?ilo fA?elon
مفعول فاعلات مفاعيل فاعلن
مضارع مثمن اخرب مکفوف محذوف
1004
- U - - - U - - - U - - - U -
fA?elAton fA?elAton fA?elAton fA?elon
فاعلاتن فاعلاتن فاعلاتن فاعلن
رمل مثمن محذوف
1005
U - - - U - - - U - - - U - - -
mafA?ilon mafA?ilon mafA?ilon mafA?ilon
مفاعيلن مفاعيلن مفاعيلن مفاعيلن
هزج مثمن سالم
1006
U - - - U - - - U - -
mafA?ilon mafA?ilon fa?ulon
مفاعيلن مفاعيلن فعولن
هزج مسدس محذوف
1007
- - U - U - - - - U - U - -
maf?ulo fA?elAton maf?ulo fA?elAton
مفعول فاعلاتن مفعول فاعلاتن (مستفعلن فعولن مستفعلن فعولن)
مضارع مثمن اخرب
1008
- - U U - - U U - - U U - -
maf?ulo mafA?ilo mafA?ilo fa?ulon
مفعول مفاعيل مفاعيل فعولن
هزج مثمن اخرب مکفوف محذوف
1009
- U - - U - U - U U -
fA?elAton mafA?elon fa?alon
فعلاتن مفاعلن فعلن
خفیف مسدس مخبون محذوف
1010
- U - - - U - - - U -
fA?elAton fA?elAton fA?elon
فاعلاتن فاعلاتن فاعلن
رمل مسدس محذوف
1011
- U U - U - U - - U U - U - U -
mofta?elon mafA?elon mofta?elon mafA?elon 
مفتعلن مفاعلن مفتعلن مفاعلن
رجز مثمن مطوي مخبون
1012
- - U U - - - - - U U - - -
maf?ulo mafA?ilon maf?ulo mafA?ilon
مفعول مفاعيلن مفعول مفاعيلن
هزج مثمن اخرب
1013
U U - U - U - - U U - U - U - -
fa?alato fA?elaton fa?alato fA?elaton
فعلات فاعلاتن فعلات فاعلاتن
رمل مثمن مشکول
1014
U - U - U U - - U - U - U U - -
mafA?elon fa?alAton mafA?elon fa?alAton
مفاعلن فعلاتن مفاعلن فعلاتن
مجتث مثمن مخبون
1015
- - U U - U - U - -
maf?ulo mafA?elon fa?ulon
مفعول مفاعلن فعولن
هزج مسدس اخرب مقبوض محذوف
1016
- - U - - - - U - -
mostaf?elAton mostaf?elAton
مستفعلاتن مستفعلاتن
رجز مرفل
1017
- U U - - U - U - U U - -
mofta?elon fA?elAto mofta?elon fa?
مفتعلن فاعلات مفتعلن فع
منسرح مثمن مطوي منحور
1018
- - U - - - U - - - U - - - U -
mostaf?elon mostaf?elon mostaf?elon mostaf?elon
مستفعلن مستفعلن مستفعلن مستفعلن
رجز مثمن سالم
1019
- U U - - U - - U U - - U -
mofta?elon fA?elon mofta?elon fA?elon
مفتعلن فاعلن مفتعلن فاعلن
منسرح مثمن مطوي مکشوف
1020
- U - U - - - - U - U - - -
fA?elAto maf?ulon fA?elAto maf?ulon
فاعلات مفعولن فاعلات مفعولن
مقتضب مثمن مطوي مقطوع
1021
- U U - - U U - - U -
mofta?elon mofta?elon fA?elon
مفتعلن مفتعلن فاعلن
سريع مسدس مطوي مکشوف
1022
U - - U - - U - - U - -
fa?ulon fa?ulon fa?ulon fa?ulon
فعولن فعولن فعولن فعولن
متقارب مثمن سالم
1023
U - - U - - U - - U -
fa?ulon fa?ulon fa?ulon fa?al
فعولن فعولن فعولن فعل
متقارب مثمن محذوف
1024
- U U - - U U - - U U - - U U -
mofta?elon mofta?elon mofta?elon mofta?elon
مفتعلن مفتعلن مفتعلن مفتعلن
رجز مثمن مطوي
1025
U U - - U U - - U U - - U U - -
fa?alAton fa?alAton fa?alAton fa?alAton
فعلاتن فعلاتن فعلاتن فعلاتن
رمل مثمن مخبون
1026
U U - - U U - - U U -
fA?elAton fa?alAton fa?alon
فعلاتن فعلاتن فعلن
رمل مسدس مخبون محذوف
1027
U - - U U - - U U - - U U - -
mafA?ilo mafA?ilo mafA?ilo fa?ulon
مفاعيل مفاعيل مفاعيل فعولن
هزج مثمن مکفوف محذوف
1028
U U - - U - U - U U - - U - U -
fa?alAton mafA?elon fa?alAton mafA?elon
فعلاتن مفاعلن فعلاتن مفاعلن
خفيف مثمن مخبون
1029
- - U U - U - U - - -
maf?ulo mafA?elon mafA?ilon
مفعول مفاعلن مفاعيلن
هزج مسدس اخرب مقبوض سالم
1030
- U - - - U - - - U - - - U - -
fA?elAton fA?elAton fA?elAton fA?elAton
فاعلاتن فاعلاتن فاعلاتن فاعلاتن
رمل مثمن سالم
1031
- - U - U U - - - U - U U -
mostaf?elon fa?alon mostaf?elon fa?alon
مستفعلن فعلن مستفعلن فعلن
بسيط مثمن مخبون"""

"""## Prostody Helpers"""

ans2ud = {}
ud2phoneme = {}
categories = []
informative_prostody = {}
prostody_categories = prostody_categories.splitlines()

for i in range(0, len(prostody_categories), 5):
  _ans = prostody_categories[i]
  _ud = prostody_categories[i + 1].replace(" ", "",  -1)
  _phoneme = prostody_categories[i + 2]
  _arabic = prostody_categories[i + 3]
  _persian = prostody_categories[i + 4]
  ans2ud[_ans] = _ud
  ud2phoneme[_ud] = _phoneme
  categories.append(_ans)
  informative_prostody[_ud] = {
    "ans": _ans,
    "phoneme": _phoneme,
    "arabic": _arabic,
    "persian": _persian,
  }

from sklearn import preprocessing

categoryEncoder = preprocessing.LabelEncoder()
categories = categoryEncoder.fit_transform(categories)

categories[:5]

"""# Modeling"""

!pip install simpletransformers

import torch
from simpletransformers.classification import ClassificationModel, ClassificationArgs
import pandas as pd
import logging


logging.basicConfig(level=logging.INFO)
transformers_logger = logging.getLogger("transformers")
transformers_logger.setLevel(logging.WARNING)

# Preparing train data
def process_line(prop):
  t, u, a = prop
  if (a == '@#$%'):
    return None
  
  t1, t2 = t.split("*")

  token_1 = g2p(t1, tidy=False).replace("  ", "#", -1).replace(" ", "", -1).replace("#", " ", -1)
  token_2 = g2p(t2, tidy=False).replace("  ", "#", -1).replace(" ", "", -1).replace("#", " ", -1)

  u1, u2 = u.split("*")

  return [f'{t1} {u1} {t2} {u2}', categoryEncoder.transform([a])[0]]

data = map(process_line, make_data_loader(develeopment=True))
data = list(filter(lambda x: x, data))

from sklearn.model_selection import train_test_split
train_data, eval_data = train_test_split(data, test_size=0.1, random_state=1400, shuffle=False)

import numpy as np
num_labels = np.unique([i[1] for i in data]).__len__()

train_df = pd.DataFrame(train_data)
train_df.columns = ["text", "labels"]

# Preparing eval data
eval_df = pd.DataFrame(eval_data)
eval_df.columns = ["text", "labels"]

# Optional model configuration
model_args = ClassificationArgs(num_train_epochs=10, overwrite_output_dir=True)

# Create a ClassificationModel
model = ClassificationModel(
    'bert',
    'bert-base-cased',
    num_labels=num_labels,
    use_cuda=torch.cuda.is_available(),
    args=model_args
) 

# Train the model
model.train_model(train_df)

# Evaluate the model
result, model_outputs, wrong_predictions = model.eval_model(eval_df)

data_test = map(process_line, make_data_loader(develeopment=False))
data_test = filter(lambda x: x, data_test)
X_test, y_true = [], []
for x, y in data_test:
  X_test.append(x)
  y_true.append(y)

# # Make predictions with the model
predictions, raw_outputs = model.predict(X_test)

from sklearn.metrics import accuracy_score

print('accuracy >> ', accuracy_score(y_true, predictions))